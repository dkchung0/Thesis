%\input{preamble}
%%\usepackage{wallpaper}                                          % 使用浮水印
%%\CenterWallPaper{0.6}{images/ntpu.eps}                           % 浮水印圖檔
%\begin{document}
%\fontsize{12}{22pt}\selectfont
%\cleardoublepage
%%\thispagestyle{empty}
%\setlength{\parindent}{2em}
\chapter{文獻回顧}

\section{旅遊評論}

	Gretzel與Kyung (2008)說明了消費者所留下的旅遊評論，越來越重要，作者經由對於TripAdvisor的用戶進行調查，結果表明這些旅遊評論，對消費者主要用途是為其住宿決定提供有用的參考訊息，而另外也提到，這些旅遊評論對於旅館業者，提供了對於旅館營運和行銷有很大的啟示。
	
	Song等(2019)也做過實驗去驗證，使用TripAdvisor這個訂房網站，對於來自日本北海道7個不同區域的評論樣本提取滿意程度，與政府自己實施的旅客滿意度調查，通過Pearson相關係數，算出與其中6個區域的調查紀錄存在強烈的正相關，也說明了這些線上評論的可行性。
	
	透過Schuckert等(2015)統計2004到2013關於旅館評論的學術論文，並經由論文回顧以及分析，明確解釋對於旅館或研究人員如何利用旅館評論，去挖掘有用資訊，並進行電子商務策略。並經由訂房網站上香港旅館資訊，從資料能看到熱門旅館中超過7成都採用了線上回復管理，目的是阻止負面口碑的傳播，也能盡快去改進旅館內的缺點。
	
\newpage

\section{特徵提取}

	對於找出關鍵字，Ramos (2003)透過TF-IDF去尋找語料庫重要的詞，當作在查詢的關鍵字，而且證明了這個簡單的算法，很有效地能找到與這個關鍵字相關信息的文檔，對於查詢檢索系統有很大的幫助，但作者也指出TF-IDF有侷限性，TF-IDF不會考慮詞與詞之間的關係，每個單詞都是獨立的，所以無法處理同義字和單複數的問題。
	
	除了TF-IDF可以提取文本特徵，Chen與Wang (2012)提出一種基於聯合條件熵和遺傳算法的特徵提取方法，聯合條件熵是給定條件下的一組變量的不確定性度量，作者指出當這組特徵詞變量的不確定越小時，越能代表該文本的特徵詞，用此方法可以找到理想的文本特徵。
	
	但對於不同的文本，採用的方法也可能不太一樣，像是Zhao等(2017)也提出了一種基於Word2Vec和Textrank的關鍵字提取方法，則為了去解決社群網路短文本的問題，如TF-IDF這類的方法在社群網路上的表現不好，因為需要大量的長文本去計算詞頻和逆文檔頻率，作者適用的這套方法在Twitter的資料，表現較其他傳統提取關鍵字的方法還要好。
	
	Wang與Zhang (2017)提出一種完全基於深度學習找尋關鍵字的方法，運用雙向長短記憶循環神經網路，去自動提取關鍵字，其中作者是將不同n-gram的字詞，以頻率高低進行排序，將排名較高的當作關鍵字類的標籤，接著把關鍵字提取當作一個分類問題，去計算每個類標籤在文本的頻率，最後將高頻類的標籤當作最後的關鍵字，對於六種產品的中文評論進行的實驗表明，此方法有很高的關鍵字提取準確率。
	
	
\newpage
	
\section{模型表現}

	Mikolov等(2013)提出了Word2Vec，以及二種不同的訓練方式來計算詞向量，分別是CBOW以及Skip-gram，比起傳統方法，Word2Vec能夠從大量的資料中學習到詞向量，且訓練速度也得到很大的提升，最後得到詞向量還能夠去表達在句中的詞義，模型甚至能做到詞向量的線性運算。Mikolov等(2013)是再對於前面的Skip-gram的模型去改進，為了去解決當詞庫太大時，出現計算複雜度偏高的問題，作者提出了Hierarchical Softmax和負採樣的方式去提高模型的運算效率。
	
	Mitra等(2007)提出了一個LS-SVM的模型，作者有說明分類器是使用RBF Kernel函數，透過潛在語意分析的技術去獲得語義的信息 ，再去進行文本分類，研究結果則是標題分類準確率高達99.9%
	
	Patel與Meehan (2021)提到為了想要去分析虛假Reddit上的假新聞，運用到文字模型和機器學習分類模型去做預測，作者的文字模型選用了CountVectorizer和TF-IDF，機器學習模型則使用邏輯斯迴歸、MultinominalNB、SVM，而作者的研究結果是指出運用CountVectorizer配上MultinominalNB會得到最高的準確率(Accuracy)。
	
	Huang等(2021)說明了評論文本的價值性，作者為了解決當兩種情感極性同時出現，情感分類邊界難以去區分是哪一種類的問題，透過潛在狄利克雷分配的主題模型，進行文本特徵數量的拓展，再透過SVM、RF、GDBT、XGBoost去進行文本分類，實驗結果則是表明這些步驟有助於去增強情感邊界的分類能力，模型則是透過TF-IDF提取特徵後由GBDT分類表現最佳。
	
\newpage
	
\section{推薦方法}

	Xia等(2015)說明了在分類或分群上，餘弦相似度是一種優先會考慮的方法，原因是不只理論很直觀，表現出來的結果又有效，當相似性度量的定義明確時，能夠處理很多種類的問題。作者也提出了一種基於餘弦相似度改良的方法，稱作餘弦相似度集成（CSE），透過多個弦相似度學習器去計算相似度，也經過作者的數據集，去證明CSE優於其他計算相似度的方法。
	
	Schafer等(2007)在論文中介紹了協同過濾的核心概念、自適應網絡的主要的用途，也提及協同過濾的理論部分，以及怎麼使用這個方法，去設計一個推薦系統。也說明了協同過濾這個方法，是如何讓自適應網絡的個性化技術變得強大，協同過濾是使用其他人的意見過濾或是評估項目的過程，當擁有大量數據時，推薦系統能夠更精準去推薦。
	
	
	
%\end{document}




