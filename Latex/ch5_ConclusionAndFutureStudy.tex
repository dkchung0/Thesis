%\input{preamble}
%%\usepackage{wallpaper}                                          % 使用浮水印
%%\CenterWallPaper{0.6}{images/ntpu.eps}                           % 浮水印圖檔
%\begin{document}
%\fontsize{12}{22pt}\selectfont
%\cleardoublepage
%\thispagestyle{empty}
%\setlength{\parindent}{2em}

\chapter{結論與研究建議}

	本章節第一節會對研究結果做出總結論，研究結果包含找到特定國家的旅館負面關鍵字，以及去比較不同的詞向量模型和機器學習組合，在不同的模型指標下的結果，最後透過文字探勘和資訊度量方法，配合相似度計算實施特定的旅館推薦。第二節會對於本研究給出建議和未來方向。

\section{總結論}

	資料是經由網路爬蟲技術，抓取Booking.com這個訂房網站的資料，選擇使用歐洲兩個國家冰島和希臘熱門旅館的旅客評論資料。將資料運用TF-IDF和Conditional Entropy結合的方法，分別去定義國家特定的負面關鍵字，如冰島這個國家的旅館，可以透過旅客給出的「dead fly」和「dirty bathroom」，去改善旅館的衛生環境，而去希臘玩的旅客給出「rude staff」和「poor condition」，說明了希臘旅館的接待員需要去改善服務態度，以防旅客有不好的旅遊體驗。
	
	因為在訂房網站上，大部分的旅遊評分或是評論，還是以正面評論居多，負面評論占少數，導致我們的資料類別出現嚴重的不平衡，所以給出的應對方案，是去調整模型的類別權重，也透過不同的詞向量模型對上隨機森林和SVM去預測少數類別(真實負面評論旅客)，得知提高類別的權重會影響Recall的表現，也能發現其實類別權重數字的選擇，不能只看資料不平衡的程度，雖說大部分組合提高權重值與Recall的表現呈現遞增，但是少部分的組合Recall卻呈現持平或是下降，所以不同的模型組合也有不同的類別權重選擇，因應不同的資料需要透過多次模擬和驗證。
	
	將GBDT這個模型和兩種衡量模型好壞的指標加入比較後，可以發現Word2Vec的兩種模型CBOW和Skip gram配上隨機森林時，表現劣於詞袋模型和TF-IDF模型，而在GBDT中是與詞袋模型的組合最佳，但是當CBOW和Skip gram配上SVM，模型表現大幅優於其他模型組合，而當中Skip gram和SVM這個模型更是略勝一籌，在兩個國家資料上，三種模型指標大致上都優於其他模型組合，猜測是對於語義去訓練詞向量的Word2Vec，更能去表達句子內的上下文，有助於提升預測能力，而Tang等(2008)也用過改良的SVM去處理資料高度不平衡的問題，所以在不平衡的文字資料上，用Skip gram和SVM這個模型組合去預測真實負面評論旅客，能得到很好的模型表現。
	
	透過Skip gram和SVM的模型組合，抓出這些真實負面評論旅客後，針對其留下的負面評論，進一步透過文字探勘的方法，從找出特定國家的負面關鍵字，轉為縮小資料顆粒度，去尋找每間熱門旅館代表的負面關鍵字，最後去計算與旅客負面評論的餘弦相似度，而推薦方式則是去列出相似度得分愈低的旅館，想法是希望真實負面評論旅客遇到的問題，不再下一間旅館又發生，透過這樣的方法，就能將適合的旅館推薦給這些真實負面評論旅客。
	
	本研究運用了Conditional Entropy來確認負面評論中的關鍵字，提出的假設是負面評論關鍵字都是極其嚴重的問題，如同出現在負面類的關鍵字，如果也頻繁的出現正面類，其字就無法確切的代表負面類，所以有必要將衡量字詞分類的不確定性大小，視為找尋負面類關鍵字的過程之一。也驗證了餘弦相似度的做法，對於評論句子與關鍵字詞句之間相似度計算的可行性。
	
\newpage

\section{建議和未來方向}

	本研究對於文字預處理的部分，只針對英文文本去做研究，將非英文的評論全透過翻譯轉為英文評論，因為翻譯結果不太可能百分之百能表達評論者所想的，途中可能會喪失評論者其評論背後的涵義，所以未來研究可能不能只考慮單一語系，考慮加入世界的主流語言像是中文、西班牙語。而資料的來源會再多考慮其他的訂房網站，可能遇到每個訂房網站的受眾群不太一樣，導致資料太過偏頗，也能增加資料的多樣性，減少遇到overfitting的可能性。
	
	文字探勘中TF-IDF和Conditional Entropy的方法，雖然在本研究能找出關鍵字，但考慮都是字詞出現的頻率，容易出現重複的關鍵字，像是「dirty room」和「room dirty」，這兩個詞其實只是順序不一樣。還有因為旅遊負面評論的特性，常常留下的評論會出現「bad experience」或是「bad hotel」，這樣的關鍵字雖能看出負面態度，但是又太抽象，旅館業者無法透過這樣的關鍵字發現具體的問題，所以在未來研究找尋關鍵字的方法，會想透過語義或者句義，將一段評論以幾個關鍵字來表示，例如:「This hotel is dirty.」、「Lots of rubbish on the hotel floor.」，這兩句都是說到住宿環境的問題，希望在找尋關鍵字視為同個問題，會考慮Wang與Zhang (2017)的作法，將提取關鍵字的問題轉為多分類問題。實際作法會參考大量的負面評論，定義出旅館負面評論語料庫，再去經由一些能夠將「語義」表達出來的模型，去實施多個類別的分類，這樣每則負面評論就以語料庫中的其中一種負面字去表達，最後選擇頻率最高的負面字當作旅館代表的負面字，有助於解決找出來的字太過抽象的問題。
	
	本研究對於遇到不平衡資料的問題，不僅是用調整類別權重的方式，也有從資料出發，使用統計抽樣的方法，如過採樣(Over Sampling)的方法SMOTE，去實施分類的預測，但出來的結果卻不盡理想，未來會考慮用其他改良的採樣方法，像是加入欠採樣(Under Sampling)的方法Tomek Link，去更好的進行分類。
	
\newpage
	
	對於本研究在不平衡資料的分類上，是先將文字轉為詞向量，再配合機器學習模型去做預測，是個兩階段的過程。在未來研究時，當硬體條件達到水平，嘗試使用自然語言領域的語言模型像是LSTM、Bert，這樣的語言模型省略了將文字轉為詞向量這個步驟，透過建立神經網路直接實行分類預測。接著進一步研究模型的訓練時間以及模型的表現，去比較這些語言模型和現在使用方法的的績效。
	
	最後對於本研究實施的推薦方法，因為只有單純的評論資料，所以無法立即對於新的旅客做出推薦，因為此方法需要有評論才能做推薦，假設能透過訂房網站得到留言評論者的詳細資料，可考慮加入協同過濾的方式去做推薦，像是現在美國的影音串流平台Netflix，其推薦系統內就有運用到協同過濾演算法的概念，對於未來建置旅館推薦系統預計會有不錯的成效。

%\end{document}










